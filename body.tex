\section{Introduction}
\label{sec:intro:0}

The Vera C. Rubin Observatory’s Data Preview 1 (DP1) marks an important milestone in preparing for the forthcoming Legacy Survey of Space and Time (LSST), offering a valuable opportunity to test and validate scientific tools and workflows on precursor imaging data~\citep{RTN:095}. Among the core scientific objectives of LSST is the estimation of photometric redshifts (photo-zs) for billions of galaxies, enabling extragalactic astrophysics and cosmological analyses that rely on redshift estimates and distributions.  Accordingly the Rubin project developed a roadmap to providing high-quality photo-zs for the scientific community~\citep{DMTN:049}.

Although photo-z are not a DP1, deliverable as part of the ``Photo-z Science Unit'' was asked to generate robust photo-z estimates for every galaxy in DP1 using the available multi-band imaging on a best-effort basis, laying the groundwork for future large-scale applications.  This effort required integrating realistic data processing with scalable machine learning techniques capable of delivering precise redshift predictions across varied galaxy populations.

To accomplish this task, we employed the RAIL (Redshift Assessment Infrastructure Layers) software package, a flexible and modular platform designed for photo-z estimation and evaluation\citep{RAIL}.  Specifically, we used RAIL to train photo-z estimation algorithms on hiqh-quality redshift training sets cross-matched to the DP1 photometric catalog.  

This note describes the resulting best-effort photo-z catalogs, which should be regarded as extremely preliminary, tools used and the steps taken to generate those catalogs.  In addition, we describe relevant features of the DP1 photometric data, the spectroscopic calibration datasets and the results photo-z catalogs.  

%RAIL supports a range of machine learning and template-fitting algorithms and offers streamlined pipelines for training, testing, and applying photo-z models.  We used RAIL to train supervised machine learning models on redshift training sets cross-matched to the DP1 photometric catalog.  These training sets, drawn from publicly available catalogs in the Extended Chandra Deep Field South (ECDFS), comprise galaxies with known spectroscopic redshifts, grism redshifts, and high-quality photo-z's from deep multi-band imaging.  These training sets enable machine learning models within RAIL to learn the mapping between galaxy colors and redshifts, enabling photo-z estimation for every galaxy detected in DP1.

% This effort demonstrates the pipeline's readiness for larger-scale deployment in future data releases.  In collaboration with the broader DP1 processing campaign, we provided valuable feedback on data quality, training requirements, and model generalization, while highlighting the importance of large, high-quality redshift training sets.  Moreover, the use of RAIL established a reproducible and extensible framework for photo-z estimation that can evolve in parallel with LSST’s data volume and complexity.  This initial deployment in DP1 thus serves as a prototype for future photo-z workflows in the LSST era.

\section{Data}
\label{sec:data:0}

\subsection{Rubin DP1}
\label{sec:data:dp1}

The Rubin Observatory’s Data Preview 1 (DP1) dataset is the first public release of Rubin observatory imaging data processed through the LSST Science Pipelines, serving as a critical testbed for scientific and technical validation ahead of full LSST operations.  DP1 is based on observations from the LSST commissioning camera (LSSTComCam) and includes multi-band optical imaging in u, g, r, i, z and y filters over several square degrees of sky.  The dataset consists of processed images, source catalogs, and associated metadata, all formatted using the Rubin Data Butler system in the same way as full LSST data products.  Although smaller in scale than future LSST datasets, DP1 offers realistic photometric measurements, object detection, and data structures, making it an invaluable resource for developing and testing algorithms for tasks such as photo-z estimation, object classification, and data quality assessment.


\subsubsection{Data preparation}
\label{sec:data:dp1:preparation}

The Rubin Data Management pipeline measures multiple types of object photometry, the first stage in creating a photometric redshift catalog was to determine which measured photometry we would use as inputs.  In this note, we generally use the 1.0 arcsecond Gaussian Aperture fluxes and their associated errors, e.~g.~\texttt{u\_gaap1p0Flux} and \texttt{u\_gaap1p0FluxErr}.  These fluxes should provide good measures of consistent galaxy colors within the defined aperture, ideal for photo-z estimation, though they may not necessarily reflect the colors of the overall galaxy if there is a significant color gradient and the galaxy is larger than the 1.0 arcsecond aperture.  This choice of photometric measurement may not be ideal, and investigation into the optimized set of photometric inputs will continue into the future.   The only exceptions to this are that we used the \texttt{i\_psfFlux} in the initial broad data cuts, and that we briefly explored several of the other fluxes as part the initial validation of our analysis pipelines. 

Preparing object catalog data for photometric redshift algorithm training and estimation included five steps:

\begin{enumerate}
\item{Applying quality cuts to the object catalog.   We developed a  selection for the training and test datasets (\textbf{match\_gold}), and two additional selections for full DP1 catalogs: one applicable for fields with observations in only four bands (\textbf{gold\_4\_band}), the other for fields with observations in all six bands (\textbf{gold}).  These selections are described below.}
\item{Converting fluxes in nJy to AB magnitudes ($m_\text{AB} = -2.5 \log_{10}(f_\nu / \text{nJy}) + 31.4$)}
\item{De-reddening to account for Galactic dust.  We use the SFD dust maps\citep{SFD}.}
\item{Cross-matching objects with reference catalogs that include redshift information as described in Sec.~\ref{sec:data:reference}.}
\item{Shuffling and splitting the resulting catalog into ``training'' and ``test'' data sets.}
\end{enumerate}

The data selection criteria that we used were:
\begin{itemize}
\item{\strong{match\_gold}: see Sec.~\ref{sec:data:reference}}
\item{\strong{gold}: \code{Detection in 'ugrizy'  \&\& i\_psfFlux / i\_psfFluxErr > 5 \&\& ( g\_extendedness > 0.5 || r\_extendedness > 0.5)}}
\item{\strong{gold\_4\_band}: \code{Detection in 'griz' \&\& i\_psfFlux / i\_psfFluxErr > 5 \&\& ( g\_extendedness > 0.5 || r\_extendedness > 0.5)}}
\end{itemize}

To create the ``training'' and reserved ``test'' data sets, we followed steps 1--5 in the ECDFS field, while for the complete DP1 data set we followed steps 1--3.


\subsubsection{Object Catalog}
\label{sec:data:dp1:obj_catalog}

For estimating the photometric redshift of the object catalogs, we follow step 1--3 in Section~\ref{sec:data:dp1:preparation} to the ``ECDFS'', ``EDFS'', ``Rubin SV 95 -25'' fields and apply the \textbf{gold} target selection. In ``Rubin SV 38 7'', DP1 only has observation in 4 bands (``griz''), therefore we applied preparation step 1--3 and the \textbf{gold\_4\_band} target selection to the ``Rubin SV 38 7'' field. 

We applied the models trained on the 6 bands training set (\textbf{gold}) to the ``ECDFS'', ``EDFS'' and ``Rubin SV 95 -25'' object catalogs, and models trained on the 4 bands training set (\textbf{gold\_4\_band}) to the ``Rubin SV 38 7'' catalog. 

All of these datasets are summarized in Tab.~\ref{tab:dataset}.

\begin{table*}
\centering
\begin{tabular}{lll}
 \hline
    Data set & Selection & Number of objects\\
 \hline
 \hline
 DP1 & None & \eac{How many} \\ 
 ECDFS+EDFS+SV\_95 & \textbf{gold} & 375,610\\
 SV\_38 & \textbf{gold\_4\_band} & 169,034\\
 Training & \textbf{match\_gold}  & 12,000\\
 Test & \textbf{match\_gold}  & 2,172 \\
 \hline
\end{tabular}
\caption{ Summary of the datasets used in this work. Note that to train models on four-band photometry, we used the same \textbf{match\_gold} training and test sets as for six-band photometry, but configured the algorithms only to use the 'griz' bands.}
\label{tab:dataset}
\end{table*}


\subsubsection{Data properties}
\label{sec:data:dp1:properties}

We have developed tools to generate diagnostic plots of both the input object catalogs and the photo-z estimates as part of our data analysis.
Fig.~\ref{fig:dp_mags} shows histograms of the AB magnitudes in 1.0 arcsecond apertures of objects in the ``test'' dataset, which includes an explicit magnitude cut, $m_{i} < 26.0$.
Fig.~\ref{fig:dp_mag_i_v_redshift} shows the correlation between magnitude and redshift for all objects in the reserved ``test'' data set.  
Fig.~\ref{fig:dp_color_v_redshift} shows the ``adjacent band colors'', i.e., $u-g$, $g-r$, $r-i$, $i-z$, $z-y$ versus redshift for the same, with a series of SED templates (as used by template-fitting algorithms, see Sec.~\ref{sec:method:template}) overlaid.  
Finally, Fig.~\ref{fig:dp_color_v_color} shows the color-color correlations for the same.  In all cases, the 1.0 arcsecond aperture magnitudes are used for plotting.

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures/mags.pdf}
    \caption{1.0 arcsecond Gaussian Aperture (Gaap) magnitudes (in AB system) of objects in each of the six Rubin filter bands in the ``test'' dataset.  These aperture magnitudes were used as the inputs for the photo-z algorithms.}
    \label{fig:dp_mags}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures/mag_i_v_redshift.pdf}
    \caption{1.0 arcsecond Gaussian Aperture (Gaap) i-band magnitude versus redshift for all objects in the ``test'' dataset.}
    \label{fig:dp_mag_i_v_redshift}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[height=7in]{figures/color_v_redshift.pdf}
    \caption{``Adjacent band colors'', i.e., $u-g$, $g-r$, $r-i$, $i-z$, $z-y$, in 1.0 arcsecond apertures versus redshift for all objects in the ``test'' dataset.  Colored lines represent the expected colors for the eight ``CWWSB'' SEDs described in Section~\ref{sec:method:template}, and should very roughly show the predicted range of color evolution expected for our galaxy sample.}
    \label{fig:dp_color_v_redshift}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures/color_v_color.pdf}
    \caption{Color-color correlations for all objects in the ``test'' dataset.  Colored lines represent the expected colors for the eight ``CWWSB'' SEDs described in Section~\ref{sec:method:template}, and should very roughly show the predicted color evolution expected for our galaxy sample.}
    \label{fig:dp_color_v_color}
\end{figure*}

\pagebreak

\subsection{Redshift reference sample}
\label{sec:data:reference}

The photometric estimation algorithms in RAIL require highly accurate and precise redshift estimates cross-matched to the DP1 photometric catalog to provide labeled ``training'' data sets.  We created such datasets using data drawn from publicly available catalogs in the Extended Chandra Deep Field South (ECDFS), comprising galaxies with known spectroscopic redshifts, grism redshifts, and high-quality photo-z's from deep multi-band imaging.  These training sets enable machine learning models within RAIL to learn the mapping between galaxy colors and redshifts, enabling photo-z estimation for every galaxy detected in DP1.

\begin{figure*}[b]
    \centering
    \includegraphics[width=\linewidth]{figures/redshift_reference_cat.pdf}
    \caption{
        Redshift reference sample in ECDFS.
        Left: Locations of DP1 galaxies cross-matched to objects in each reference catalog (using color scheme from middle panel).
        Many of the sets overlap in the densely-covered GOODS-S field.
        Middle: Redshift distribution of objects in the reference catalogs.
        Right: Same as middle panel with a log scale on the y-axis.
    }
    \label{fig:reference-sample}
\end{figure*}

The reference data set used to train photometric redshift algorithms can have an outsize impact on the resulting photo-z estimates, particularly for machine learning based methods.  In many ways, the galaxies with known redshifts define the flux/color to distance relation by tracing out the mapping from empirical magnitudes to redshift that the algorithms ``learn".  As such, the details of the construction of the reference sample is very important.  In an ideal case, we would prefer to have a ``representative" sample of redshifts, i.~e.~a fair sampling in terms of the color and magnitude distribution for all galaxies; however, due to the practicalities of spectrographs and expensive telescope time investment needed for deep spectroscopic campaigns, we must deal with incomplete training samples, particularly for faint and high redshift objects.  We must also determine which datasets contain ``secure" redshifts that meet some confidence threshold, and whether to include datasets from grism and many-band photo-z estimates that may contain a small fraction of incorrect redshift identifications.  We continue to refine our reference sample definition, and we may include or exclude additional samples as we investigate system performance, this note represents a current best effort, but the final selection will likely evolve.  There are also some concerns of imprinted sample variance, as the deep six-band data of DP1 is concentrated in the single ECDFS field.  Future Rubin data will cover multiple widely separated deep fields containing rich spectroscopic datasets, which will mitigate these concerns, but they may be an issue for the current DP1 estimates.  

We have compiled a large redshift reference sample in the ECDFS, consisting of spectroscopic-, grism-, and high-quality multiband photometric-redshifts (Fig.~\ref{fig:reference-sample}).
This reference sample is used to train machine learning photo-z estimators and evaluate photo-z performance.
The component redshift catalogs (described below) were combined into a single reference catalog and their respective quality flags were homogenized by defining a redshift ``confidence'' (more on this below).

When combining the component redshift catalogs, sources within $0.75''$ were identified as duplicates.
For these sources only the highest quality redshift is kept, i.e. spectroscopic redshifts are preferred over grism redshifts, which are preferred over photo-z's, and higher confidence values are preferred for redshifts of the same type.
The redshift reference catalog was then cross-matched to the ComCam DP1 catalog using a radius of $0.75''$.

Confidence, which takes values between 0.0 and 1.0, is loosely defined as the fractional probability that an individual redshift estimate is correct.
Most of the spectroscopic sets provide these estimates for their redshifts.
For the few that don't we assigned the confidence 0.95.
For the grism and multiband photo-z surveys, we set the confidence equal to $1 - f_\text{out}$, where $f_\text{out}$ is the reported outlier rate of these catalogs.
To facilitate custom quality cuts, the catalog contains flags indicating whether each redshift originates from spectroscopy (\code{type == ''s''}), grism (\code{''g''}), or multiband photo-z (\code{''p''}), as well as confidence values.
Note redshifts from grism and photo-z surveys, however, have larger scatter and bias than spectroscopic surveys (and possible incorrect redshifts if the redshift is based off of a single emission line), but these metrics are not captured by the confidence parameter.
We encourage readers to investigate the details of each component survey that comprise our reference catalog and apply their own quality cuts as suit their needs.
For example, if studying high-redshift galaxies, you might choose to include the multiband photo-z's, which increase the number of redshifts at $z > 2$ by a factor of~3 (Fig.~\ref{fig:redshift-by-type}).

We applied conservative cuts for our fiducial analyses, specifically \code{type == ''s''}, \code{confidence >= 0.95}, SNR $>= 10$ in the $i$ band (using \code{gaap1p0} fluxes).
We then did a random 80\%/20\% train/test split on this catalog, resulting in a training set of 4803 redshifts and a test set of 1201 redshifts.


\begin{table}[!p]
    \centering
    \begin{tabular}{lllll}
        \hline
        Survey & Type & Confidence & Matches& Reference \\
        \hline
        \hline
        2dFGRS & s & 1.00 & 3 & \citet{colless2001} \\
               &   & 0.99 & 4 & \\
               &   & 0.90 & 1 & \\
        2dflens & s & 1.00 & 1 & \citet{blake2016} \\
        2MRS & s & 0.95 & 1 & \citet{huchra2012} \\
        6dFGRS & s & 0.98 & 2 & \citet{jones2009} \\
        3D-HST & g & 0.99 & 5 & \citet{momcheva2016} \\
               &   & 0.95 & 277 & \\
        ASTRODEEP & s & 1.00 & 4165 & \citet{merlin2021} \\
                  & p & 0.97 & 8212 & \\
        ASTRODEEP-JWST & s & 1.00 & 594 & \citet{merlin2024} \\
                       & p & 0.92 & 628 & \\
                       &   & 0.90 & 455 & \\
        CANDELS & s & 1.00 & 53 & \citet{kodra2023} \\
                & p & 0.93 & 6 & \\
        JADES & s & 0.99 & 11 & \citet{deugenio2025} \\
              &   & 0.95 & 34 & \\
              &   & 0.90 & 24 & \\
        MOSDEF & s & 0.99 & 9 & \citet{kriek2015} \\
        NED & s & 0.95 & 847 & \citet{helou1991} \\
        OzDES & s & 0.99 & 897 & \citet{lidman2020} \\
        PRIMUS & g & 0.92 & 3653 & \citet{cool2013} \\
               &   & 0.85 & 1687 & \\
        VANDELS & s & 1.00 & 196 & \citet{garilli2021} \\
        VIMOS & s & 1.00 & 499 & \citet{balestra2010} \\
                  &   & 0.95 & 43 & \\
        VUDS & s & 1.00 & 9 & \citet{tasca2017} \\
             &   & 0.95 & 9 & \\
             &   & 0.80 & 3 & \\
        VVDS & s & 1.00 & 101 & \citet{lefevre2013} \\
             &   & 0.95 & 193 & \\
        \hline
        Total & s & & 7699 & \\
              & g & & 5622 & \\
              & p & & 9301 & \\
              & all & & 22622 & \\
        \hline
    \end{tabular}
    \caption{
        Component surveys of the redshift reference sample.
        Redshift type is denoted\\ s = spectroscopic, g = grism, p = multiband photo-z.
        Note for our fiducial analyses we applied conservative cuts on this catalog.
        Specifically, \code{type == ''s''}, \code{confidence >= 0.95}, SNR $>= 10$ in the $i$ band (using \code{gaap1p0} fluxes).
    }
    \label{tab:reference-sample}
\end{table}

\begin{figure}
    \centering
    \includegraphics{figures/redshift_distribution_by_type.pdf}
    \caption{
        Redshift distribution of the reference catalog by redshift type, denoted s = spectroscopic, g = grism, p = multiband photo-z.
    }
    \label{fig:redshift-by-type}
\end{figure}



\subsubsection{DESI Data Release 1 spectroscopic redshift dataset}
\label{sec:data:desi}


We also use data from the DESI Data Release \citep{desi-dr1} to act as an independent validation data set as it overlaps the ``Rubin SV 38-7'' (\texttt{SV\_38}) field.
The observations of this field are centered on the Abell 360 galaxy cluster which is located at $z=0.22$~\citep{A360z}.
We cross-match the DESI Bright Galaxy Sample (BGS) \citep{BGS}, Emission Line Galaxy (ELG) \citep{ELG}, and Luminous Red Galaxy (LRG) \citep{LRG} samples against the DP1 catalog using a radius of 0.5'' producing 2728  matches with 398 from the BGS sample, 1421 from ELG, and 909 from LRG.
The area of overlap and the three subsamples are shown in Fig.~\ref{fig:desi-overlap}.
This spans a redshift range of 0 to 1.6 and \textit{i}-mag of 14 to 23.9 as shown in Fig.~\ref{fig:desi-subsample-hist}; the bump at $z\approx0.25$ can be attributed to the cluster at the center of the field.


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/desi_sample_overlap.png}
    \caption{Overlap between the \texttt{SV\_38} sample and DESI subsamples. In all plots, the small blue dots are DP1 objects from ComCam and we overlay, from left to right, the BGS, LRG, and ELG subsamples with points color-coded by redshift. Each sample probes a different redshift range and is shown with the colorbar to the right of each panel.}
    \label{fig:desi-overlap}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=.8\linewidth]{figures/desi_sample_histogram.png}
    \caption{Validation set on \texttt{SV\_38} from DESI BRG, ELG, and LRG samples. Left plot: the redshift distribution of the matched subsample with BGS in blue, ELG in orange, LRG in green, and the total matched distribution in black. Right plot: \textit{i}-band magnitude as measured by ComCam versus spectroscopic redshift for all DESI matches with subsamples shown using the same color scheme as left plot.}
    \label{fig:desi-subsample-hist}
\end{figure}

If an object was included in multiple samples, when matching we restrict to the one with the largest weight as calculated by DESI DR1.
The \texttt{SV\_38} field was observed in \textit{g} (44 visits), \textit{r} (55 visits), \textit{i} (57 visits) and \textit{z} (27 visits) bands restricting our validation to the 4 band models.
Furthermore, the incomplete overlap with the BGS sample limits our ability to validate on redshifts below $z=0.5$. 


\section{Methodology}
\label{sec:method:0}

We used the RAIL as the core tool for training, and applying photometric redshift estimation models.   We also used RAIL to evaluate the model performance through a suite of diagnostic metrics using photo-z point estimates, including redshift bias, scatter (e.g., normalized median absolute deviation), and catastrophic outlier rate and to make diagnostic plots of the algorithm's performance.

We used the methodology describe below to evaluate all the algorithms listed in Tab.~\ref{tab:alg}.  Note that the \code{KNN} and \code{BPZ} algorithms will be supported by the project data management team, while the others will be supported by the wider community, the RAIL development team and DESC collaboration.


\begin{table*}
\centering
\begin{tabular}{lll}
 \hline
    Algorithm name  & Home package & Reference\\
 \hline
 \hline
 \multicolumn{3}{c}{Project Supported} \\ 
  \code{BPZ} & \href{https://github.com/LSSTDESC/rail_bpz}{\code{rail-bpz}} & \citet{Benitez:2000}\\
 \code{KNN} & \href{https://github.com/LSSTDESC/rail_sklearn}{\code{rail-sklearn}} & RAIL Paper\\
 \multicolumn{3}{c}{Commuity Supported} \\   
 \code{CMNN} & \href{https://github.com/LSSTDESC/rail_cmnn}{\code{rail-cmnn}} & \citet{Graham:2018}\\
 \code{DNF} & \href{https://github.com/LSSTDESC/rail_dnf}{\code{rail-dnf}} & \citet{2016MNRAS.459.3078D}\\
 \code{FlexZBoost}  & \href{https://github.com/LSSTDESC/rail_flexzboost}{\code{rail-flexzboost}} & \citet{Izbicki:2017}\\
 \code{GPz} & \href{https://github.com/LSSTDESC/rail_gpz_v1}{\code{rail-gpz-v1}} & \citet{Almosallam:2016}\\
 \code{LePHARE} & \href{https://github.com/LSSTDESC/rail_lephare}{\code{rail-lephare}} & \citet{1999MNRAS.310..540A}\\
 \code{TPZ} & \href{https://github.com/LSSTDESC/rail_tpz}{\code{rail-tpz}} & \citet{Carrasco-Kind:2013}\\
 \hline
\end{tabular}
\caption{
Summary of the pre-wrapped estimators/summarizers/classifiers used in this paper and described detail in~\citep{RAIL}.}
\label{tab:alg}
\end{table*}

For each algorithm, we trained Photo-z models using the spectroscopic datasets that were matched to DP1 photometric sources as described in Sec.~\ref{sec:data:reference}, serving as labeled examples with known redshifts.   Specifically, we used the \texttt{rail\_project} package (see \ref{sec:method:rail_project} to run RAIL’s \href{https://github.com/LSSTDESC/rail_pipelines/blob/main/src/rail/pipelines/estimation/pz_all.py}{PzPipeline}.  The pipeline consists of ``Informing'' or training the models on the ``training'' dataset, and using those models in ``Estimation'' and ``Evaluation'' stages on the reserved ``test'' dataset to evaluate the algorithm performance.  We also used \texttt{rail\_project} to run RAIL’s  \href{https://github.com/LSSTDESC/rail_pipelines/blob/main/src/rail/pipelines/estimation/estimate_all.py}{EstimatePipeline}, to perform the photometric redshift estimation on data sets without spectroscopic matches for all of the algorithms.

In this work we are only using the magnitudes in the six (or four) available bands as inputs to the photometric estimation.  As stated in
Sec.~\ref{sec:data:dp1:properties}, we systematically use the \code{gaap1p0} version of the fluxes, as these are considered the most reliable for color estimation.


\subsection{Template fitting based estimators}
\label{sec:method:template}

RAIL’s template-based fitting algorithms (\code{Lephare} and \code{BPZ}, see references in Tab.~\ref{tab:alg} for more details) estimate photometric redshifts by comparing observed galaxy photometry to a set of predefined theoretical or empirical galaxy templates.  These templates represent a range of galaxy spectral energy distributions (SEDs) that are meant to span the expected range of galaxy types observed in the Universe.  Synthetic model fluxes are computed by redshifting each SED to a set grid of values and convolving with the Rubin filter curves,  which characterizes the expected variation in observed colors with redshift.  Our algorithms calculate the chi-square/likelihood for each SED at each grid point by comparing the model fluxes in our photometric bands to the observed fluxes and uncertainties.  This process enables the algorithm to determine the relative likelihood for each redshift for a given galaxy by identifying the template that best matches its observed color signature.  An optional empirical Bayesian prior can also be applied to produce a posterior probability rather than a straight likelihood if information on the expected distributions are available.  The training phase for these algorithms consist mostly of preparing pre-computed tables for the expected fluxes in each filter band for each SED template. 

Two sets of templates are included in the \texttt{rail\_base} software package and used in this note: the ``CWWSB'' templates that are the default templates used by \texttt{rail\_bpz} and described in \citet[]{Coe:06}, consisting of eight total SEDs, one Elliptical template, two Spiral templates, and five Irregular/Starburst template.  In this note, these SEDs are used to compute synthetic colors that we compare to the observational data in Figures~\ref{fig:dp_color_v_redshift} and~\ref{fig:dp_color_v_color}, but are otherwise not used.  The second template set consists of those described in \citet[]{Ilbert:09}, consisting of 31 synthetic SEDs (including some that are ``interpolated'' between adjacent templates by taking the mean of the two SEDs).  These SEDs are included with \texttt{rail\_lephare} as ``COSMOS\_mod.list'' in the \texttt{lephare-data} package.  These SEDs are used by both template codes \texttt{rail\_bpz} and \texttt{rail\_lephare}.  The 31 base SEDs contain no internal dust extinction, \texttt{rail\_lephare} is configured to include dust automatically, while \texttt{rail\_bpz} required dust to be added explicitly, and additional SED templates that include internal extinction added to the input SED list. \code{LePhare} also includes a set of stellar and AGN SEDs, which are available in the \texttt{lephare-data} package.


\subsection{Machine learning based estimators}
\label{sec:method:machine_learning}

RAIL’s machine learning algorithms (\code{CMNN}, \code{DNF}, \code{FlexZBoost}, \code{GPZ}, \code{KNN}, \code{TPZ}) are described in detail in the publications listed in Tab.~\ref{tab:alg}.  In short these algorithms attempt to perform a regression analysis to estimate the redshift from the input photometric data.   It is a well-known limitation of machine learning algorithms that they exhibit biases when presented with non-representative data, or are asked to extrapolate results outside region of their training data.


\subsection{Analysis framework and bookkeeping software}
\label{sec:method:rail_project}

The \texttt{rail\_projects} software package within the RAIL ecosystem provides an essential framework for managing and organizing large-scale photometric redshift estimation workflows.  It acts as a project management and book-keeping tool that helps users streamline their research, especially when working with complex or large datasets, like those associated with the Rubin DP1 data.  The primary focus of \texttt{rail\_projects} is to offer a systematic way to track different stages of data processing, model training, evaluation, and results across multiple experiments, ensuring that all tasks are well-documented and reproducible.

Additionally, \texttt{rail\_projects} facilitates the management of large datasets by organizing data into structured directories and providing interfaces for batch processing.  It allows users to scale up their work to handle not only large catalogs of objects but also multiple datasets and redshift estimation tasks.  The package ensures that datasets and models are kept in sync across various stages, from raw input data to intermediate results to final outputs, and makes it easier to systematically export data coherent products.


\subsection{Data exploration and algorithm optimization}
\label{sec:method:optimization}

We explored dozens of different configuration settings, coverage analysis choices such as which flux measurements to use, the machine learning hyper-parameters, which sets templates to use, among others.   The \href{https://github.com/LSSTDESC/rail_project_config/blob/main/dp1/dp1.yaml}{dp1/dp1.yaml} configuration file (see Sec.~\ref{sec:products:configuration}) captures the set of configurations that we tested.  

After examining the performance of the algorithms under different configurations, we settled on a set of optimized parameters for each algorithm and on the \code{gaap\_1p0} fluxes to produce the ``best-effort'' catalogs for DP1.   These optimized configurations parameters are captured in the \ref{https://github.com/LSSTDESC/rail_project_config/blob/main/dp1/dp1.yaml}{dp1/dp1\_v1.yaml} configuration file.


\section{Data products}
\label{sec:products:0}

In the course of this work, we generated several data products, including redshift estimates and a variety of others that can be used to reproduce those estimates and to facilitate thorough evaluation of the algorithm performance.  These products include: configuration files, see Sec.\ref{sec:products:configuration}, ancillary inputs, see Sec.\ref{sec:products:algo_files}, trained models, see Sec.\ref{sec:products:models}, redshift estimates, see Sec.\ref{sec:products:qp_ensembles}, summary statistics,  see Sec.\ref{sec:products:summary_statistics}, and performance monitoring plots, see Sec.\ref{sec:products:peformance_plots}, all of which are essential for understanding the quality of the photometric redshift estimates and for refining the algorithms.   Together, these data products provide a comprehensive framework for conducting, managing, and evaluating photometric redshift estimation workflows in Rubin DP1.  They ensure that the process is not only scientifically rigorous but also organized and reproducible, enabling effective collaboration and ongoing refinement of photometric redshift techniques.


\subsection{Configuration files}
\label{sec:products:configuration}

The configuration files, collected \href{https://github.com/lsstdesc/rail_project_config}{in the GitHub \code{rail\_project\_config}} repository, provide the necessary parameters and settings to control the various stages of the redshift estimation process, are a key element of \texttt{rail\_projects} workflow.  These files typically include specifications for the photometric bands used (e.g., g, r, i, z), the algorithm choices (e.g., template fitting or machine learning methods), details about data pre-processing, such as feature normalization and handling of missing data.  These configuration files also specify the training and validation dataset splits, hyper-parameters for machine learning models, and paths for input/output data.  These files are essential for ensuring reproducibility and for sharing the exact settings used in different redshift estimation runs, enabling other researchers to replicate or extend the analysis. 


\subsection{Ancillary input files}
\label{sec:products:algo_files}

In addition to the configuration files, we require ancillary inputs such as the galaxy spectral energy distribution (SED) templates and the filter throughputs.  Galaxy SED templates are collections of theoretical or observed spectra for galaxies at different redshifts and with different properties (e.~g.~, galaxy type, age, star formation history).  These templates are used by template-fitting algorithms to model the expected galaxy colors as a function of redshift, allowing for the estimation of photometric redshifts by comparing observed colors to those predicted by the templates.  Two SED sets are employed in this note, they are each described in Section~\ref{sec:method:template}.

The filter throughputs specify the characteristics of the fiducial observational filter transmission curves, and are used in Rubin DP1, including their corresponding central wavelengths.  These filter curves are employed in calculating the synthetic fluxes or magnitudes expected from each of the SED templates used in template-fitting algorithms, and for matching observational data to predicted theoretical values, e.~g.~the predicted colors shown in Figure~\ref{fig:dp_color_v_redshift}.


\subsection{Estimator data models}
\label{sec:products:models}

After training, the trained models for each photometric redshift estimation algorithm are stored as serialized files, either in Pickle (for Python-based models) or YAML (for model configurations) format.  These models encapsulate the learned relationships between photometric features (such as magnitudes and colors) and redshift values, allowing them to be applied to new data for redshift estimation.  These files store the final state of the model, including the weights, biases, and other learned parameters for machine learning models.  In the case of template-fitting methods, the corresponding model files may include the template sets and the fitting parameters.  The Pickle or YAML format ensures that the models can be easily loaded, applied to new datasets, and evaluated in future studies.


\subsection{Redshift estimates stored as QP ensembles}
\label{sec:products:qp_ensembles}

The per-object redshift estimates generated by the photometric redshift algorithms are stored in \code{qp} files.  These files serve as containers for storing the redshift predictions for each object in the dataset before any detailed statistical analysis or final reporting.  In the qp files, each galaxy’s redshift estimate is stored in a format that is compatible with the algorithm providing the estimate.   Specifically, for each object we store distribution $p(z)$, which, depending on the algorithm, maybe represent a posterior probability, a likelihood, a conditional likelihood, or just a hunch as to redshift of the object in question.   These \code{qp} files are designed to be lightweight and easy to query, allowing users to quickly retrieve the redshift estimates for individual objects.  The structure of \code{qp} files is optimized for efficient access and data retrieval, making it easier for users to process and analyze large numbers of photometric redshift estimates across large datasets like Rubin DP1.  Additional information, including usage examples, about \code{qp} and \code{qp} files is available at \href{https://qp.readthedocs.io/en/main/}{https://qp.readthedocs.io/en/main/}.


\subsection{Per-Object Point Estimates}
\label{sec:products:summary_statistics}

In addition to the raw redshift estimates, the \code{qp} files also store per-object point estimates in the form of an ancillary table.  These estimates include crucial information about the quality and reliability of each photometric redshift estimate, such as the uncertainty in the redshift prediction (e.g., the confidence interval or standard deviation or, the likelihood score (in the case of probabilistic models).   This table will eventually includes flags for identifying objects with low-confidence estimates or those that may be outliers.  These summary statistics are important for evaluating the overall performance of the redshift estimation algorithms on an object-by-object basis and are often used to filter out low-quality or problematic redshift estimates before conducting larger statistical analyses.


We also generate meta catalog file that collects the Object ID, magnitude information, and point estimates. The point estimates are named by ``\{algorithm\}\_z\_\{point estimate name\}''.
Here is a list of the point estimates and summary statistics that are stored for each algorithm and the corresponding column names:
\begin{enumerate}
    \item \textbf{mean}: is the per-object expectation of redshift given by the PDF. 
    \item \textbf{median}: is the 50\% percentile of the PDF.
    \item \textbf{mode}: is the redshift that yields maximum PDF evaluated on 301 grid points between $z=0$-$3$. 
    \item \textbf{err68\_lower(upper)}: is the 16th (84th) percentile of the per-galaxy PDF, which correspond to the 1$\sigma$ confidence interval. 
    \item \textbf{err95\_lower(upper)}: is the $2.5$th ($97.5$th) percentile of the per-galaxy PDF, which correspond to the 2$\sigma$ confidence interval. 
\end{enumerate}
Fig.~\ref{fig:pdf} shows an example of the $p(z)$ distribution, point-estimates and summary statistics for a single object.

Yes.\begin{figure*}
    \centering
    \includegraphics[width=1.0\linewidth]{figures/pdf.pdf}
    \caption{Single object $p(z)$ estimate, showing both the PDF, and the CDF, as well as the summary statistics described in the text.}
    \label{fig:pdf}
\end{figure*}


\subsection{Performance Monitoring Plots}
\label{sec:products:peformance_plots}

Finally, we produced standardized performance monitoring plots as part of the photometric redshift workflow.  These plots provide visual representations of the model's performance, allowing users to assess how well the redshift estimates align with the true redshifts from the spectroscopic training data.  Common plots include:

\begin{itemize}
\item{Input dataset characterization plots, as shown in Sec.~\ref{sec:data:dp1:properties}.}
\item{Scatter plots to visualize the relationship between the predicted and true redshifts, highlighting any systematic biases or non-linearities.}
\item{Redshift comparison plots, e.g., the bias or width of the redshift residuals, $\frac{z_{\rm phot} - z_{\rm spec}}{1 + z_{\rm spec}}$, as a function of redshift or object magnitude.}
\end{itemize}

To robustly summarize the distribution of residuals while minimizing the influence of outliers, we compute biweighted statistics following a two-step procedure. First, we apply an iterative $3\sigma$ clipping to the input array using \texttt{scipy.stats.sigmaclip}, repeating the clipping process \texttt{nclip} times (default is 3). This removes extreme outliers before computing robust estimators. We then calculate the \textit{biweight location} and \textit{biweight scale} of the clipped subset using the \texttt{astropy.stats} functions, which yield robust analogs to the mean and standard deviation, respectively. 

In addition, we compute two outlier rates: the \textit{relative outlier rate}, defined as the fraction of values in the original sample that deviate from zero by more than $3\times$ the biweight scale, and the \textit{absolute outlier rate}, defined as the fraction of values exceeding a fixed threshold set by \texttt{self.config.abs\_out\_thresh}. This framework provides both robust central moments and a diagnostic of extreme deviations in the full sample.

Examples of the two latter types of plots for the \texttt{BPZ} and \texttt{KNN} algorithms are shown in Sec.~\ref{sec:performance:0}


\section{Data Distribution}
\label{sec:distribution:0}

To support both the Rubin community and the DESC, we will distribute these data products in several different ways:
\begin{enumerate}
\item{Via the Rubin Data Butler (see Sec.~\ref{sec:distribution:butler}).}
\item{Via the Photo-z Server (see Sec.~\ref{sec:distribution:linea}).}
\item{Directly as files at the USDF and NERSC (see Sec.~\ref{sec:distribution:files}).}
\item{Via LSDB (see Sec.~\ref{sec:distribution:lsdb})}
\end{enumerate}

In each of these distribution mechanisms there are a number of metadata that are used as fields in defining specific data products.  In particular:

\begin{itemize}
\item{\textbf{algo}: specifies a particular photo-z estimation algorithm (see Tab.~\ref{tab:alg}),}
\item{\textbf{selection}: specifies a particular data selection (see Sec.~\ref{sec:data:dp1:preparation}),}
\item{\textbf{flavor}: specifies a particular set of configuration parameters,}
\item{\textbf{dataset}: specifies a particular dataset (see Sec.~\ref{tab:dataset}).}
\end{itemize}


\subsection{Distribution via the Rubin Data Butler}
\label{sec:distribution:butler}

Creation of photometric redshift estimates using RAIL in the Rubin DM framework and distribution via the Rubin Data Butler is supported the \href{https://github.com/lsst-dm/meas_pz}{\code{meas\_pz}} software package for DM supported algorithms and by the \href{https://github.com/lsst-dm/meas_pz}{\code{meas\_pz\_extensions}} software package for the community-supported algorithms described in this note.

For DP1, the following objects stored in the data butler at USDF and NERSC are listed in Tab.~\ref{tab:butler}.

\begin{table*}
\centering
\begin{tabular}{ll}
 \hline
Dataset type & Description \\
 \hline
 \hline
\multicolumn{2}{l}{Collection: \code{pretrained\_models/pz/DP1/\{selection\}/\{flavor\}}} \\ \hline
\code{pzModel\_algo} & Estimator models (see ~\ref{sec:products:models}) \\ \hline
\multicolumn{2}{l}{Collection: \code{LSSTComCam/runs/DRP/DP1/pz/DM-51523/\{selection\}/\{flavor\}/\{attempt\}}} \\  \hline
\code{pz\_estimate\_algo} & QP ensembles (see ~\ref{sec:products:qp_ensembles}) \\
\code{pz\_algo\_config} & Configuration parameters (see ~\ref{sec:products:configuration}) \\
\code{pz\_algo\_log} & Log files \\
\code{pz\_algo\_metadata} & Processing metadata \\
 \hline
\end{tabular}
\caption{Photo-z related objects stored in the Rubin Data Butler.}
\label{tab:butler}
\end{table*}


\subsection{Distribution via the Photo-z Server}
\label{sec:distribution:linea}
% Julia

The \href{https://pzserver.linea.org.br/}{Photo-z Server (or PZ Server)} is a web-based service available for the LSST community to create and host PZ-related lightweight data products. It relies on the infrastructure of the Brazilian Independent Data Access Center and is developed and maintained by LIneA as part of the Brazilian in-kind contribution program.  

The PZ server is open to any LSST member with a valid RSP account without the need for an extra local registry. Users can log into the system simply using the RSP credentials. 

All data products described in this document 
will be % are also 
hosted on the PZ Server, along with their respective metadata and documentation. There are two ways to access these data products: 

\subsubsection{From the PZ Server website} 

Data products are listed both on the 'Rubin PZ Data Products' page (for official data products released or recommended by LSST DM) and 'User-generated data products' for data products produced or uploaded by the LSST community members. The DP1 PZ data products described in this document
overlwill be 
%are 
available in the first one. %, and their links to individual data product details pages are listed below: 

% \begin{itemize}
%     \item Spec-z Catalog \href{https://pzserver-dev.linea.org.br/}{<product name placeholder>}
%     \item Training and Test Sets \href{https://pzserver-dev.linea.org.br/}{<product name placeholder>}
%     \item Estimator Data Models \href{https://pzserver-dev.linea.org.br/}{<product name placeholder>}
%     \item Redshift estimates \href{https://pzserver-dev.linea.org.br/}{<product name placeholder>}
% \end{itemize} 

\subsubsection{Via the \code{pzserver} Python library}

Similar to the RSP, the PZ Server provides an API interface that enables users to access data through Python scripts from any location, provided they know the product name as registered on the server. 
 
If it is the first time using the library, it must be installed via \code{pip} in the terminal or in a notebook cell: \code{pip install pzserver}

Then, the \code{PzServer} class opens the remote connection to the PZ Server database. An access token is required for authentication. The token can be generated by users on the PZ Server website (top right corner menu on the home page).    

\begin{verbatim}
from pzserver import PzServer
pz_server = PzServer(token="<paste your access token here>")  
\end{verbatim}

To display the product metadata and download it to the local working directory (if not in a Jupyter notebook, replace \code{display} for \code{get}):   
\begin{verbatim}
pz_server.display_product_metadata(<product_id>)
pz_server.download_product(product_id, save_in=".")
\end{verbatim}

Alternatively, it is possible to load a table directly into memory as a Pandas DataFrame or Astropy Table. For instance, to load a training set:  

\begin{verbatim}
training_set = pz_server.get_product(<training_set_id>)
training_set.display_metadata()
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TO DO: 
% Add examples with the correct product_id 
% of datasets mentioned in this document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

A tutorial notebook with examples for all \code{pzserver} methods is available on the \href{https://github.com/linea-it/pzserver/blob/main/docs/notebooks/pzserver_tutorial.ipynb}{\code{pzserver} library's repository on GitHub}.


\subsection{Distribution as files at USDF and NERSC}
\label{sec:distribution:files}

All of the test and training files, the outputs from runs used to optimize the model hyperparamters, as well as from the optimized models, the photo-z estimates for the entire DP1 dataset, are all available in \code{rail\_projects}-managed shared project area at both NERSC and USDF.  These data products are listed in Tab.~\ref{tab:project_area}.

\begin{table*}
\centering
\begin{tabular}{ll}
 \hline
Object type  & Relative Path \\
 \hline
 \hline
Training data sets  & \code{data/train/*.hdf5} \\ 
Test data sets  & \code{data/test/*.hdf5} \\ \hline
\multicolumn{2}{l}{In : \code{pz/projects/dp1/pipelines}} \\ \hline
Pipeline configurations & \code{\{pipeline\}\_\{flavor\}.yaml} \\ \hline
\multicolumn{2}{l}{In : \code{pz/projects/dp1/data}} \\ \hline
Estimator models & \code{\{selection\}\_\{flavor\}/model\_inform\_\{algo\}.pkl} \\
QP ensembles (for test data) & \code{\{selection\}\_\{flavor\}/output\_estimate\_\{algo\}.pkl} \\
QP ensembles (for other data) & \code{\{selection\}\_\{flavor\}/\{dataset\}/output\_estimate\_\{algo\}.pkl} \\
 \hline
\end{tabular}
\caption{Photo-z related files in the \code{rail\_projects}-managed shared project areas.}
\label{tab:project_area}
\end{table*}


\subsection{Distribution via LSDB}
\label{sec:distribution:lsdb}

The Large Survey DataBase (LSDB) will host the DP1 data on the USDF and the Canadian IDAC RSP. The DP1 data will be turned into Hierarchical Adaptive Tiling Scheme (HATS) format. LSDB enables researchers to load large datasets with limited memory, and fast cross match to other surveys like DESI DR1 and GAIA DR3. 

The photo-z point estimates for DP1 in the \texttt{ECDFS},\texttt{EDFS}, \texttt{Rubin\_SV\_95\_-25}, and \texttt{Rubin\_SV\_38\_7}  will be served as a single tabular catalog in the LSDB. The location on the USDF for this catalog is \texttt{/sdf/data/rubin/shared/lsdb\_commissioning/dp1\_pz\_hats}. 


\section{Performance}
\label{sec:performance:0}

We evaluated all the algorithms listed in Tab.~\ref{tab:alg} for both scientific and technical performance.

\subsection{Redshift estimator performance}
\label{sec:performance:pz}

In this section, we present the performance of photometric redshift algorithms that go into the DP1 photo-$z$ data product. We mainly evaluated the performance by the ``test'' catalog which consist of 2,147 galaxies randomly drawn from the cross-match between the DP1 object catalog in ECDFS with the spectroscopic galaxies described in Section~\ref{sec:data:reference}. Additionally, we cross match the DP1 object catalog in the \texttt{Rubin\_SV\_38\_7} field with the DESI DR1 BGS, LRG and ELG galaxies as a secondary validation set. 

Specifically, we ran the pz (Inform $\rightarrow$ Estimate $\rightarrow$ Evaluate) pipeline to train models for per-object $p(z)$ estimation on the training data set, use those models to obtain photo-z estimates for the test data set, and then evaluate the performance of the photometric point-estimate of the redshift against the spectroscopic estimates.

For each algorithms, we produce a set of performance monitoring plots, described in Section~\ref{sec:products:peformance_plots}. In Fig~\ref{fig:perf_gold}, we show examples of these performance monitoring plots for two algorithms: \code{knn} and \code{bpz} for the 6-band models and using the mode for the specific point estimate. Fig.~\ref{fig:perf_gold_4_band} shows the performance monitoring of \code{knn} and \code{bpz} when 4-bands are used. In the scattering plot, the mean, standard deviation, 3$\sigma$ outliers and absolute outliers of 
\begin{equation}
\label{eq:dz}
    \Delta z = \frac{z_{\rm phot} - z_{\rm spec}}{1+z_{\rm spec}}
\end{equation}
are shown in legend. We summarized these statistics in Table~\ref{tab:photoz_metrics}.

\begin{figure*}
    \centering
    \includegraphics[width=0.45\linewidth]{figures/zestimate_v_ztrue_hist2d_knn.png}
    \includegraphics[width=0.45\linewidth]{figures/zestimate_v_ztrue_hist2d_bpz.png} \\
    \includegraphics[width=0.45\linewidth]{figures/biweight_stats_v_redshift_knn.png}
    \includegraphics[width=0.45\linewidth]{figures/biweight_stats_v_redshift_bpz.png} \\
    \includegraphics[width=0.45\linewidth]{figures/biweight_stats_v_mag_knn.png}
    \includegraphics[width=0.45\linewidth]{figures/biweight_stats_v_mag_bpz.png}    
    \caption{Estimator performance on the ``gold'' (six-band') dataset.  Top row: photometric point estimate of the redshift versus spectroscopic redshift for \code{KNN} (left) and \code{bpz} (right).   Middle row: performance metrics, (width and bias of residual, and outlier rate) versus spectroscopic redshift.    Bottom row, performance metrics versus i-band magntidue.}
    \label{fig:perf_gold}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=0.45\linewidth]{figures/zestimate_v_ztrue_hist2d_knn_4.png}
    \includegraphics[width=0.45\linewidth]{figures/zestimate_v_ztrue_hist2d_bpz_4.png} \\
    \includegraphics[width=0.45\linewidth]{figures/biweight_stats_v_redshift_knn_4.png}
    \includegraphics[width=0.45\linewidth]{figures/biweight_stats_v_redshift_bpz_4.png} \\
    \includegraphics[width=0.45\linewidth]{figures/biweight_stats_v_mag_knn_4.png}
    \includegraphics[width=0.45\linewidth]{figures/biweight_stats_v_mag_knn_4.png}    
    \caption{Estimator performance on the ``gold\_4\_band'' (four-band') dataset.  Top row: photometric point estimate of the redshift versus spectroscopic redshift for \code{KNN} (left) and \code{bpz} (right).   Middle row: performance metrics, (width and bias of residual, and outlier rate) versus spectroscopic redshift.    Bottom row, performance metrics versus i-band magntidue.}
    \label{fig:perf_gold_4_band}
\end{figure*}

\begin{table}[ht]
\centering
\caption{Performance metrics for photo-$z$ algorithms using 6-band data, with 4-band results shown in parentheses.}
\begin{tabular}{lcccc}
\hline
\textbf{Algorithm} & \textbf{Bias} & \textbf{$\sigma$} & \textbf{3$\sigma$ Outlier Rate} & \textbf{$\Delta z>0.2$ Outlier Rate} \\
\hline
FlexZBoost & 0.000 (0.000) & 0.0246 (0.0274) & 0.215 (0.221) & 0.113 (0.124) \\
kNN        & -0.002 (-0.000) & 0.0301 (0.0285) & 0.205 (0.245) & 0.128(0.147) \\
CMNN       & 0.000 (-0.002) & 0.0369 (0.0729) & 0.227 (0.212) & 0.160 (0.226) \\
DNF        & -0.002 (-0.001) & 0.041 (0.0327) & 0.189 (0.215) & 0.138 (0.121) \\
TPZ        & -0.001 (-0.002) & 0.050 (0.0524) & 0.154 (0.156) & 0.117 (0.127) \\
GPz        & 0.032 (0.018) & 0.166 (0.106) & 0.056 (0.110) & 0.260 (0.198) \\
BPZ        & -0.018 (-0.015) & 0.0425 (0.060) & 0.198 (0.197) & 0.146 (0.186) \\
LePhare    & -0.012 (-0.015) & 0.0344 (0.0699) & 0.207 (0.175) & 0.139 (0.185) \\
\hline
\end{tabular}
\label{tab:photoz_metrics}
\end{table}



\subsubsection{Redshift estimation quality flags}
\label{sec:performance:pz}

Applying a simple cut on the RMS of the $p(z)$ distribution can dramatically reduce the catastrophic outlier rate.  In Fig.~\ref{fig:perf_quality_cut} we show how the efficiency and purity obtained on the test sample varies with a single additional cut, $x$ in $\sigma_{p(z)} < x$.   In Fig.~\ref{fig:scatter_quality_cut} we show how applying a cut at $\sigma_{p(z)} < 0.15$ improves the scatter of the photometric redshift point-estimate versus spectroscopic redshift distribution.  As fainter objects and objects at higher redshift often have larger p(z) RMS values, cuts on RMS will likely result in relative shifts in the magnitude and redshift distribution depending on the cut value.

\begin{figure*}
    \centering
    \includegraphics[width=0.45\linewidth]{figures/efficiency.pdf}
    \includegraphics[width=0.45\linewidth]{figures/purity.pdf} \\
    \includegraphics[width=0.45\linewidth]{figures/purity_v_effic.pdf} \\
    \caption{Efficiency (top left) and ``purity'', i.e., fraction of objects with $\frac{\delta z}{1 + z_{\rm spec}} < 0.20$) (top right) versus quality cut, $x$ in $\sigma_{p(z)} < x$.   Bottom, purity version efficiency with cut value shown by the color scale.   The red star shows the point for a cut value  $\sigma_{p(z)} < 0.15$.}
    \label{fig:perf_quality_cut}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=0.45\linewidth]{figures/tpz_scatter_orig.pdf}
    \includegraphics[width=0.45\linewidth]{figures/tpz_scatter_clean.pdf} \\
    \caption{Estimator performance for \code{TPZ} without (left) and with (right) a quality cut of $\sigma_{p(z)} < 0.15$.}
    \label{fig:scatter_quality_cut}
\end{figure*}


\subsubsection{Validation in the \texttt{SV\_38} field}

We cross-matched our photo-$z$ estimates with the DESI DR1 LSS galaxies (BGS, LRG, and ELG) in the \texttt{SV\_38} field. This cross-matched catalog can be served as additional validation for our photo-$z$ results. In Fig.~\ref{fig:sv_validation}, we show the median photometric redshift estimates versus the DESI spectroscopic redshifts for a selection of representative photo-$z$ algorithms. Each panel corresponds to a different algorithm, allowing us to visually assess the bias, scatter, and potential outlier behavior across a wide redshift range. Overall, the agreement with DESI DR1 spectroscopic redshifts provides a robust sanity check on the performance of our methods in the early LSST data regime.

\begin{figure*}
\centering
\includegraphics[width=0.32\linewidth]{figures/fzboost_mode_desi.png}
\includegraphics[width=0.32\linewidth]{figures/knn_mode_desi.png}
\includegraphics[width=0.32\linewidth]{figures/cmnn_mode_desi.png}
\includegraphics[width=0.32\linewidth]{figures/dnf_mode_desi.png}
\includegraphics[width=0.32\linewidth]{figures/tpz_mode_desi.png}
\includegraphics[width=0.32\linewidth]{figures/gpz_mode_desi.png}
\includegraphics[width=0.32\linewidth]{figures/bpz_mode_desi.png}
\includegraphics[width=0.32\linewidth]{figures/lephare_mode_desi.png}
\caption{Mode photometric redshift estimates versus DESI DR1 spectroscopic redshifts for galaxies in the \texttt{SV\_38} cross-matched sample. Each panel shows results from a different photo-$z$ algorithm: FlexZBoost, kNN, CMNN, DNF, TPZ, GPz, BPZ, and LePhare (from left to right, top to bottom). These comparisons provide an external validation of photo-$z$ performance using Large-Scale Structure spectroscopic redshifts samples DESI.}
\label{fig:sv_validation}
\end{figure*}






\subsection{Technical performance}
\label{sec:performance:technical}

Tab.~\ref{tab:tech_perf} shows compute times and file sizes for both the training and estimation phases of the analysis.    The metrics from the training phase were taken from running the algorithm's ``Inform'' stages on USDF on the ``training'' dataset of ~13,000 objects.    The metrics from the estimation phase were taken from algorithm's ``Inform'' stages on USDF on the ``test'' datasets of ~2,000 objects.

\begin{table*}
\centering
\begin{tabular}{lllll}
 \hline
  Algorithm name  & \multicolumn{2}{c}{Training}  &  \multicolumn{2}{c}{Estimation} \\
   & Time [s] & Model Size [MB] &  Speed [ms / object] & Data Size [b / object] \\  
 \hline
 \hline
 \multicolumn{5}{c}{Project Supported} \\ 
  \code{BPZ} & $< 5$ & 1 & 1.5-10 & $\sim$ 2400\\
 \code{KNN} & 8 - 30 & 1 & 0.6-1.5 & $\sim$ 240 \\
 \multicolumn{5}{c}{Community Supported} \\   
 \code{CMNN} &  $< 5$ & 1 & 2.4 & 54 \\
 \code{DNF} &  $< 5$ & 2 & 0.6 & $\sim$ 2400 \\
 \code{FlexZBoost}  & 55 - 100 & 35 - 50 & 4-13 & $\sim$ 2400\\
 \code{GPz} & 10 - 15 & 1 & < 0.5 & 32 \\
 \code{LePHARE} & 300 - 600 & 1 & 50 - 180 & $\sim$ 2400 \\
 \code{TPZ} & 5-20 & 7 - 300 & 7 - 120 & $\sim$ 2400 \\
 \hline
\end{tabular}
\caption{
  Algorithm compute times and files sizes.   The algorithms were trained on $\sim 10$k objects and evaluated on $2$k objects.  The variations shown reflect the differences in processing times with different sets of hyper-parameters.
}
\label{tab:tech_perf}
\end{table*}

We note that the technical performance requirements depend heavily on the scientific use case.  For example, in supernova cosmology, the number of objects will be in the 100's of thousands, while for weak-lensing cosmology, it will be in the billions.  Accordingly, these give very different constraints on the required processing speed of the photo-z estimation.  While seconds per object is supportable for supernova cosmology, weak-lensing will require processing times in the milliseconds ($ms$) per object range. 


\section{Limitations and Caveats}
\label{sec:limitations:0}

The photo-z estimates described in this note were done on a best-effort basis by members of the ``Photo-z Science Unit'' and are not official Rubin data products.  As such, the release of the various DP1-related data products comes with a number of caveats.

\begin{itemize}
\item{The size and depth of the training set seriously limits the robustness of the training past a redshift of $z \simeq 1.5$.  See in particular Fig.~\ref{fig:dp_mag_i_v_redshift}.}
\item{In general, photo-z algorithms do not perform well with objects with marginal detections or with non-detections in several bands.  Simply put, the photometric uncertainties in such objects often overwhelms the information that is present and the photometric estimates are very uncertain.  See Fig.~\ref{fig:faint_object_pdf} for an example of the PDF of such an object.   Similarly, see, Fig~\ref{fig:faint_objects} as an illustration of how the accuracy of a photo-z point-estimate degrades significantly for faint objects.}
\item{Taking points (1) and (2) together, we do not advise to use any of the provided DP1 photo-z estimates without applying cuts on the detection significance or the width of the $p(z)$ distribution, or both.}
\item{While we did put some work into optimizing the performance of the various algorithms, this was by no means comprehensive, and we urge caution in drawing any conclusions about the relative merits of the algorithms.}
\item{The training and test sets were drawn from the same set of spectroscopically matched objects.  As such, the training set is fairly representative of the test set.   On the other hand, the full DP1 catalog does not have any spectroscopic selections applied, so the training and test sets will not be representative of the full DP1 data set.}
\end{itemize}

\begin{figure*}
    \centering
    \includegraphics[width=0.45\linewidth]{figures/bad_pdf.pdf}
    \caption{Example of a $p(z)$ distribution for a faint object is not detected in all bands.  (In this case the object was only significantly detected in 'g' and 'r' bands).}
    \label{fig:faint_object_pdf}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=0.45\linewidth]{figures/tpz_scatter_faint.pdf}
    \caption{Point-estimates versus spectroscopic redshifts for all galaxies in the reserved test set with $m_{i} > 23.5$, showing the degradation in estimation performance for faint objects.}
    \label{fig:faint_objects}
\end{figure*}


\section{Summary and Conclusion}
\label{sec:summary:0}

This note describes an initial calculation of photometric redshifts on the Rubin Data Preview 1 dataset using the tools and workflows developed specifically for this purpose by the Photo-z Science Unit.  These early results are very promising, we show that we can successfully match Rubin data with spectroscopic samples in the ECDFS field with deep six-band Rubin coverage to create a reference sample and run our software pipelines to generate a catalog of individual object redshifts consisting of both point 1D redshift PDFs and point estimate redshifts.  We show results for eight photo-z algorithms using a reserve set of redshifts, and see that photo-z performance is in-line with expectations both in terms of our redshift predictions and for compute times.  We also test our estimates against an independent set of redshifts from the \texttt{SV\_38} field with shallower coverage and imaging in only four of the six Rubin bands.  We describe available data products and anticipated methods to access them.  Overall, this is a very successful initial test of photo-z pipelines.

However, work will continue on several fronts to further optimize the performance of our redshift predictions.  As mentioned earlier in the note, the definition of the true redshift reference sample used to train our algorithms has a large impact on results, being the ``truth" used to define the flux/color-to-redshift mapping that is inherent to photo-z estimation.  We will work to refine our reference sample definition, which objects to include/exclude based on quality flags, explore the tradeoffs of including grism and many-band photo-z estimates with larger redshift uncertainties in our training sample, and other such effects.  As more and more Rubin data is taken, areal coverage is increasing, including coverage of additional deep calibration fields with existing spec-z datasets.  This will naturally improve photo-z performance.  Expansion of reference redshifts will also enable the development of improved object flagging for identifying which redshifts are trustworthy and those which are likely to be incorrect.

We will also continue to examine the Rubin photometry and evaluate the performance of multiple measurement algorithms.  In this note we used Gaussian Aperture (Gaap) fluxes and magnitudes, as they are expected to produce consistent colors.  We will undertake a thorough exploration of multiple fluxe measurements (e.~g.~cModel, Sersic, additional Gaap apertures) to test which combinations lead to the best photo-z estimates, as well as combinations like using multiple aperture magnitudes that may contain information on the galaxy light profile that could help to constrain redshift.  As we are still in the engineering and testing phase of the project, there is ongoing work to characterize system performance, and improved understanding of the system will likely lead to better photo-z performance.  For example, there may be some hints that u-band fluxes are overestimated and u-band uncertainties underestimated at faint magnitudes (see the high redshift u-g colors in Fig.~\ref{fig:dp_color_v_redshift} and figures in~\citet{RTN:095}).  DP1 data was obtained using ComCam, while future data releases will use LSSTCam, and thus performance for DP2 and beyond may be shaped by slight differences between the two instruments.  

In this analysis, while there was some optimization of code-specific parameters for the individual estimators, e.~g.~the number of neighbors used for \code{KNN}, the number of trees used for \code{TPZ}, it was not comprehensive.  In addition, the optimal values will likely change slightly as we refine both our spectroscopic reference sample and our photometric inputs.  A thorough exploration of the code parameters will happen as we converge on our final photometric and spectroscopic setup.

[mention somewhere that we expect feedback from science users as they explore the data and discover issues that we have not anticipated, and that we will incorporate that feedback]

Key takeaway: these results are far from final, there is ongoing work to optimize photo-z performance.  We have plans in place and will continue to refine as new data arrives, and these plans should lead to improved redshift performance. (need to rephrase this ane make it more "we rocked it, yo!" positive).


% We rocked it, yo!


\pagebreak



